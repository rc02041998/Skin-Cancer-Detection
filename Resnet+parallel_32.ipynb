{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f298580",
   "metadata": {
    "id": "7f298580"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "np.random.seed(123)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical  \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras import backend as K\n",
    "import itertools\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6285afb",
   "metadata": {
    "id": "d6285afb",
    "outputId": "6e88078c-6e18-4583-dccf-da2787038c1a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ISIC_0000002.jpg.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ISIC_0000004.jpg.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ISIC_0000026.jpg.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ISIC_0000029.jpg.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ISIC_0000030.jpg.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            image_name  target\n",
       "0           0  ISIC_0000002.jpg.jpg       1\n",
       "1           1  ISIC_0000004.jpg.jpg       1\n",
       "2           2  ISIC_0000026.jpg.jpg       1\n",
       "3           3  ISIC_0000029.jpg.jpg       1\n",
       "4           4  ISIC_0000030.jpg.jpg       1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_0 = pd.read_csv('0.csv')    # reading the csv file\n",
    "train_set_0.head()\n",
    "train_set_1 = pd.read_csv('1.csv')    # reading the csv file\n",
    "train_set_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89afffd9",
   "metadata": {
    "id": "89afffd9",
    "outputId": "b2a68c3e-1f9a-4aa7-b311-3447b5cb21dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2233/2233 [00:02<00:00, 821.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "train_image = []\n",
    "\n",
    "for i in tqdm(range(train_set_0.shape[0])):\n",
    "    img = tf.keras.utils.load_img('0/' + train_set_0['image_name'][i],target_size=(224,224,3))\n",
    "    img = tf.keras.utils.img_to_array(img)\n",
    "    img = img/255\n",
    "    train_image.append(img)\n",
    "\n",
    "X = np.array(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "092adcf3",
   "metadata": {
    "id": "092adcf3",
    "outputId": "0629c713-5d8b-4f8b-b67e-409524f4a2a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1872/1872 [00:02<00:00, 835.13it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "train_image = []\n",
    "\n",
    "for i in tqdm(range(train_set_1.shape[0])):\n",
    "    img = tf.keras.utils.load_img('1/' + train_set_1['image_name'][i],target_size=(224,224,3))\n",
    "    img = tf.keras.utils.img_to_array(img)\n",
    "    img = img/255\n",
    "    train_image.append(img)\n",
    "\n",
    "Y = np.array(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "feace67d",
   "metadata": {
    "id": "feace67d"
   },
   "outputs": [],
   "source": [
    "y_0=train_set_0['target']\n",
    "y_1=train_set_1['target']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dd849e6",
   "metadata": {
    "id": "2dd849e6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_0_train, X_0_test, y_0_train, y_0_test = train_test_split(X,y_0, train_size=0.70,random_state = 42, shuffle = True)\n",
    "X_1_train, X_1_test, y_1_train, y_1_test = train_test_split(Y,y_1, train_size=0.70,random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61f7a09a",
   "metadata": {
    "id": "61f7a09a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_0_train,X_1_train))\n",
    "y_train = np.concatenate((y_0_train,y_1_train))\n",
    "X_test = np.concatenate((X_0_test,X_1_test))\n",
    "y_test= np.concatenate((y_0_test,y_1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62ae9979",
   "metadata": {
    "id": "62ae9979"
   },
   "outputs": [],
   "source": [
    "X_train_x, X_valid, y_train_x, y_valid = train_test_split(X_train,y_train, test_size=0.15,random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "539bb397",
   "metadata": {
    "id": "539bb397",
    "outputId": "564c8f56-d96f-49f2-d728-a00c110f1541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(431, 224, 224, 3)\n",
      "(431,)\n",
      "(2442, 224, 224, 3)\n",
      "(2442,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_valid.shape), print(y_valid.shape)\n",
    "print(X_train_x.shape), print(y_train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b16a3ec",
   "metadata": {
    "id": "0b16a3ec"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,  # randomly rotate images in the range \n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally \n",
    "        height_shift_range=0.1,  # randomly shift images vertically \n",
    "        ) \n",
    "\n",
    "datagen.fit(X_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "997aa04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, MaxPool2D\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import datasets,models, losses\n",
    "from keras.layers import Conv2D, MaxPool2D, Input, ZeroPadding2D\n",
    "import os\n",
    "\n",
    "def Global_attention_block(inputs):\n",
    "    \n",
    "    shape=K.int_shape(inputs)\n",
    "    x=AveragePooling2D(pool_size=(shape[1],shape[2])) (inputs)\n",
    "    x=Conv2D(shape[3],1, padding='same') (x)\n",
    "    x=Activation('relu') (x)\n",
    "    x=Conv2D(shape[3],1, padding='same') (x)\n",
    "    x=Activation('sigmoid') (x)\n",
    "    C_A=Multiply()([x,inputs])\n",
    "    \n",
    "    x=Lambda(lambda x: K.mean(x,axis=-1,keepdims=True))  (C_A)\n",
    "    x=Activation('sigmoid') (x)\n",
    "    S_A=Multiply()([x,C_A])\n",
    "    \n",
    "    return S_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cd9b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    img_inputs = keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "    conv_0 = Conv2D(16,3,strides=(1, 1), padding='same')\n",
    "    x = conv_0(img_inputs) \n",
    "    conv_0 = Conv2D(16,3,strides=(1, 1), padding='same')(x)\n",
    "    max_1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding = 'same')(conv_0)\n",
    "\n",
    "    #block 1\n",
    "\n",
    "    conv_1 = Conv2D(16,1,strides=(1, 1), padding='same')(max_1)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_1)\n",
    "    act_1 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conv_2 = Conv2D(16,3,strides=(1, 1), padding='same')(max_1)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_2)\n",
    "    act_2 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conv_3 = Conv2D(16,3,strides=(1, 1), padding='same')(max_1)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_2)\n",
    "    act_3 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conv_3 = Conv2D(16,3,strides=(1, 1), padding='same')(act_3)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_3)\n",
    "    act_3_1 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conv_4 = Conv2D(16,3,strides=(1, 1), padding='same')(max_1)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_4)\n",
    "    act_4 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conc_1 = tf.keras.layers.Concatenate(axis = -1)([act_2,act_3_1])\n",
    "    conc_1 = Conv2D(16,1,strides=(1, 1), padding='same')(conc_1)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conc_1)\n",
    "    act_conc_1 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conc_1 = Conv2D(16,3,strides=(1, 1), padding='same')(act_conc_1)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conc_1)\n",
    "    act_conc_2 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conc_2 = tf.keras.layers.Concatenate(axis = -1)([act_1,act_conc_2,act_4])\n",
    "    conv_3 = Conv2D(16,1,strides=(1, 1), padding='same')(conc_2)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_3)\n",
    "    act_conv_3 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    #add1 = tf.keras.layers.Concatenate(axis = -1)([max_1, act_conv_3])\n",
    "\n",
    "    max_2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2,2), padding = 'same')(act_conv_3)\n",
    "    \n",
    "    #second block\n",
    "    conv_1 = Conv2D(32,1,strides=(1, 1), padding='same')(max_2)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_1)\n",
    "    act_1 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conv_2 = Conv2D(32,3,strides=(1, 1), padding='same')(max_2)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_2)\n",
    "    act_2 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conv_3 = Conv2D(32,3,strides=(1, 1), padding='same')(max_2)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_2)\n",
    "    act_3 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conv_3 = Conv2D(32,3,strides=(1, 1), padding='same')(act_3)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_3)\n",
    "    act_3_1 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conv_4 = Conv2D(32,3,strides=(1, 1), padding='same')(max_2)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_4)\n",
    "    act_4 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conc_1 = tf.keras.layers.Concatenate(axis = -1)([act_2,act_3_1])\n",
    "    conc_1 = Conv2D(32,1,strides=(1, 1), padding='same')(conc_1)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conc_1)\n",
    "    act_conc_1 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conc_1 = Conv2D(32,3,strides=(1, 1), padding='same')(act_conc_1)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conc_1)\n",
    "    act_conc_2 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conc_2 = tf.keras.layers.Concatenate(axis = -1)([act_1,act_conc_2,act_4])\n",
    "    conv_3 = Conv2D(32,1,strides=(1, 1), padding='same')(conc_2)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_3)\n",
    "    act_conv_3 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    #add2 = tf.keras.layers.Concatenate(axis = -1)([max_2, act_conv_3])\n",
    "\n",
    "    max_3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2,2), padding = 'same')(act_conv_3)\n",
    "    \n",
    "\n",
    "    #3rd block\n",
    "    conv_1 = Conv2D(64,1,strides=(1, 1), padding='same')(max_3)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_1)\n",
    "    act_1 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conv_2 = Conv2D(64,3,strides=(1, 1), padding='same')(max_3)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_2)\n",
    "    act_2 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conv_3 = Conv2D(64,3,strides=(1, 1), padding='same')(max_3)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_2)\n",
    "    act_3 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conv_3 = Conv2D(64,3,strides=(1, 1), padding='same')(act_3)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_3)\n",
    "    act_3_1 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conv_4 = Conv2D(64,3,strides=(1, 1), padding='same')(max_3)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_4)\n",
    "    act_4 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conc_1 = tf.keras.layers.Concatenate(axis = -1)([act_2,act_3_1])\n",
    "    conc_1 = Conv2D(64,1,strides=(1, 1), padding='same')(conc_1)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conc_1)\n",
    "    act_conc_1 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conc_1 = Conv2D(64,3,strides=(1, 1), padding='same')(act_conc_1)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conc_1)\n",
    "    act_conc_2 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conc_2 = tf.keras.layers.Concatenate(axis = -1)([act_1,act_conc_2,act_4])\n",
    "    conv_3 = Conv2D(64,1,strides=(1, 1), padding='same')(conc_2)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_3)\n",
    "    act_conv_3 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    #add3 = tf.keras.layers.Concatenate(axis = -1)([max_3, act_conv_3])\n",
    "\n",
    "\n",
    "    max_4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2,2), padding='same')(act_conv_3)\n",
    "\n",
    "    #4th block\n",
    "\n",
    "    conv_1 = Conv2D(128,1,strides=(1, 1), padding='same')(max_4)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_1)\n",
    "    act_1 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conv_2 = Conv2D(128,3,strides=(1, 1), padding='same')(max_4)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_2)\n",
    "    act_2 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conv_3 = Conv2D(128,3,strides=(1, 1), padding='same')(max_4)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_2)\n",
    "    act_3 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conv_3 = Conv2D(128,3,strides=(1, 1), padding='same')(act_3)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_3)\n",
    "    act_3_1 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conv_4 = Conv2D(128,3,strides=(1, 1), padding='same')(max_4)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_4)\n",
    "    act_4 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conc_1 = tf.keras.layers.Concatenate(axis = -1)([act_2,act_3_1])\n",
    "    conc_1 = Conv2D(128,1,strides=(1, 1), padding='same')(conc_1)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conc_1)\n",
    "    act_conc_1 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conc_1 = Conv2D(128,3,strides=(1, 1), padding='same')(act_conc_1)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conc_1)\n",
    "    act_conc_2 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    conc_2 = tf.keras.layers.Concatenate(axis = -1)([act_1,act_conc_2,act_4])\n",
    "    conv_3 = Conv2D(128,1,strides=(1, 1), padding='same')(conc_2)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv_3)\n",
    "    act_conv_3 = tf.keras.layers.ReLU()(bn)\n",
    "\n",
    "    #add4 = tf.keras.layers.Concatenate(axis = -1)([max_4, act_conv_3])\n",
    "\n",
    "    max_5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2,2), padding='same')(act_conv_3)\n",
    "\n",
    "   \n",
    "    model=Model(inputs=img_inputs,outputs=max_5)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db65c4df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db65c4df",
    "outputId": "99793f0e-20b9-4004-d861-2ccef736859a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 224, 224, 16  448         ['input_4[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 224, 224, 16  2320        ['conv2d_36[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 112, 112, 16  0          ['conv2d_37[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 112, 112, 16  2320        ['max_pooling2d_5[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 112, 112, 16  64         ['conv2d_39[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " re_lu_34 (ReLU)                (None, 112, 112, 16  0           ['batch_normalization_34[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 112, 112, 16  2320        ['re_lu_34[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 112, 112, 16  64         ['conv2d_39[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 112, 112, 16  64         ['conv2d_41[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " re_lu_33 (ReLU)                (None, 112, 112, 16  0           ['batch_normalization_33[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_35 (ReLU)                (None, 112, 112, 16  0           ['batch_normalization_35[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 112, 112, 32  0           ['re_lu_33[0][0]',               \n",
      "                                )                                 're_lu_35[0][0]']               \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 112, 112, 16  528         ['concatenate_9[0][0]']          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 112, 112, 16  64         ['conv2d_43[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_37 (ReLU)                (None, 112, 112, 16  0           ['batch_normalization_37[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 112, 112, 16  272         ['max_pooling2d_5[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 112, 112, 16  2320        ['re_lu_37[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 112, 112, 16  2320        ['max_pooling2d_5[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 112, 112, 16  64         ['conv2d_38[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 112, 112, 16  64         ['conv2d_44[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 112, 112, 16  64         ['conv2d_42[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " re_lu_32 (ReLU)                (None, 112, 112, 16  0           ['batch_normalization_32[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_38 (ReLU)                (None, 112, 112, 16  0           ['batch_normalization_38[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_36 (ReLU)                (None, 112, 112, 16  0           ['batch_normalization_36[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 112, 112, 48  0           ['re_lu_32[0][0]',               \n",
      "                                )                                 're_lu_38[0][0]',               \n",
      "                                                                  're_lu_36[0][0]']               \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 112, 112, 16  784         ['concatenate_10[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 112, 112, 16  64         ['conv2d_45[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " re_lu_39 (ReLU)                (None, 112, 112, 16  0           ['batch_normalization_39[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 56, 56, 16)  0           ['re_lu_39[0][0]']               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 56, 56, 32)   4640        ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 56, 56, 32)  128         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " re_lu_42 (ReLU)                (None, 56, 56, 32)   0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 56, 56, 32)   9248        ['re_lu_42[0][0]']               \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 56, 56, 32)  128         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 56, 56, 32)  128         ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " re_lu_41 (ReLU)                (None, 56, 56, 32)   0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_43 (ReLU)                (None, 56, 56, 32)   0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 56, 56, 64)   0           ['re_lu_41[0][0]',               \n",
      "                                                                  're_lu_43[0][0]']               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 56, 56, 32)   2080        ['concatenate_11[0][0]']         \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 56, 56, 32)  128         ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " re_lu_45 (ReLU)                (None, 56, 56, 32)   0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 56, 56, 32)   544         ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 56, 56, 32)   9248        ['re_lu_45[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 56, 56, 32)   4640        ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 56, 56, 32)  128         ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 56, 56, 32)  128         ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 56, 56, 32)  128         ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " re_lu_40 (ReLU)                (None, 56, 56, 32)   0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_46 (ReLU)                (None, 56, 56, 32)   0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_44 (ReLU)                (None, 56, 56, 32)   0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 56, 56, 96)   0           ['re_lu_40[0][0]',               \n",
      "                                                                  're_lu_46[0][0]',               \n",
      "                                                                  're_lu_44[0][0]']               \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 56, 56, 32)   3104        ['concatenate_12[0][0]']         \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 56, 56, 32)  128         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " re_lu_47 (ReLU)                (None, 56, 56, 32)   0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 28, 28, 32)  0           ['re_lu_47[0][0]']               \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 28, 28, 64)   18496       ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 28, 28, 64)  256         ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_50 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 28, 28, 64)   36928       ['re_lu_50[0][0]']               \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 28, 28, 64)  256         ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 28, 28, 64)  256         ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_49 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_51 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 28, 28, 128)  0           ['re_lu_49[0][0]',               \n",
      "                                                                  're_lu_51[0][0]']               \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 28, 28, 64)   8256        ['concatenate_13[0][0]']         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 28, 28, 64)  256         ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " re_lu_53 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 28, 28, 64)   2112        ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 28, 28, 64)   36928       ['re_lu_53[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 28, 28, 64)   18496       ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 28, 28, 64)  256         ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 28, 28, 64)  256         ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 28, 28, 64)  256         ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " re_lu_48 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_54 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_52 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 28, 28, 192)  0           ['re_lu_48[0][0]',               \n",
      "                                                                  're_lu_54[0][0]',               \n",
      "                                                                  're_lu_52[0][0]']               \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 28, 28, 64)   12352       ['concatenate_14[0][0]']         \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 28, 28, 64)  256         ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " re_lu_55 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 14, 14, 64)  0           ['re_lu_55[0][0]']               \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 14, 14, 128)  73856       ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 14, 14, 128)  512        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " re_lu_58 (ReLU)                (None, 14, 14, 128)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 14, 14, 128)  147584      ['re_lu_58[0][0]']               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 14, 14, 128)  512        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 14, 14, 128)  512        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " re_lu_57 (ReLU)                (None, 14, 14, 128)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_59 (ReLU)                (None, 14, 14, 128)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 14, 14, 256)  0           ['re_lu_57[0][0]',               \n",
      "                                                                  're_lu_59[0][0]']               \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 14, 14, 128)  32896       ['concatenate_15[0][0]']         \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 14, 14, 128)  512        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " re_lu_61 (ReLU)                (None, 14, 14, 128)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 14, 14, 128)  8320        ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 14, 14, 128)  147584      ['re_lu_61[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 14, 14, 128)  73856       ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 14, 14, 128)  512        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 14, 14, 128)  512        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 14, 14, 128)  512        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " re_lu_56 (ReLU)                (None, 14, 14, 128)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_62 (ReLU)                (None, 14, 14, 128)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_60 (ReLU)                (None, 14, 14, 128)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenate)   (None, 14, 14, 384)  0           ['re_lu_56[0][0]',               \n",
      "                                                                  're_lu_62[0][0]',               \n",
      "                                                                  're_lu_60[0][0]']               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 14, 14, 128)  49280       ['concatenate_16[0][0]']         \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 14, 14, 128)  512        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " re_lu_63 (ReLU)                (None, 14, 14, 128)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 7, 7, 128)   0           ['re_lu_63[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, 7, 7, 2176)   0           ['conv5_block3_out[0][0]',       \n",
      "                                                                  'max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 1, 1, 2176)  0           ['concatenate_17[0][0]']         \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 1, 1, 2176)   4737152     ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 1, 1, 2176)   0           ['conv2d_70[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 1, 1, 2176)   4737152     ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 1, 1, 2176)   0           ['conv2d_71[0][0]']              \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 7, 7, 2176)   0           ['activation_4[0][0]',           \n",
      "                                                                  'concatenate_17[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 7, 7, 1)      0           ['multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 7, 7, 1)      0           ['lambda_1[0][0]']               \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 7, 7, 2176)   0           ['activation_5[0][0]',           \n",
      "                                                                  'multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 2176)        0           ['multiply_3[0][0]']             \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            2177        ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 33,785,953\n",
      "Trainable params: 33,728,993\n",
      "Non-trainable params: 56,960\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import datasets,models, losses\n",
    "from keras.layers import Conv2D, MaxPool2D, Input, ZeroPadding2D\n",
    "\n",
    "\n",
    "image_size = 224\n",
    "\n",
    "model1=tf.keras.applications.ResNet50(include_top=False,\n",
    "                       weights='imagenet',\n",
    "                       input_shape=(image_size,image_size,3))\n",
    "\n",
    "lr2 = 0.0001\n",
    "loss_fun= 'binary_crossentropy'\n",
    "\n",
    "model1_in = model1.input\n",
    "model1_out = model1.output\n",
    "\n",
    "model2 = define_model()\n",
    "\n",
    "model2_in = model2.input\n",
    "model2_out = model2.output\n",
    "\n",
    "\n",
    "conc =tf.keras.layers.Concatenate(axis = -1)([model1_out, model2_out])\n",
    "\n",
    "attend_feature_1 = Global_attention_block(conc)\n",
    "base_out=GlobalAveragePooling2D()(attend_feature_1)\n",
    "\n",
    "#base_out=GlobalAveragePooling2D()(base_out)\n",
    "x = Dense(1,activation='sigmoid')(base_out)\n",
    "\n",
    "model=Model(inputs=[model1.input,model2.input],outputs=x)\n",
    "\n",
    "\n",
    "filepath = \"resNet+parallel_32.hdf5\"\n",
    "lr_decay=ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, verbose=1)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max')\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr2,decay=0.00001),\n",
    "              loss=loss_fun,\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be2cb338",
   "metadata": {
    "id": "be2cb338"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.4154 - acc: 0.8096\n",
      "Epoch 1: acc improved from -inf to 0.80958, saving model to resNet+parallel_32.hdf5\n",
      "77/77 [==============================] - 28s 355ms/step - loss: 0.4154 - acc: 0.8096 - val_loss: 0.7089 - val_acc: 0.5545 - lr: 1.0000e-04\n",
      "Epoch 2/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.2339 - acc: 0.8927\n",
      "Epoch 2: acc improved from 0.80958 to 0.89271, saving model to resNet+parallel_32.hdf5\n",
      "77/77 [==============================] - 28s 369ms/step - loss: 0.2339 - acc: 0.8927 - val_loss: 0.7154 - val_acc: 0.5545 - lr: 1.0000e-04\n",
      "Epoch 3/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.1586 - acc: 0.9398\n",
      "Epoch 3: acc improved from 0.89271 to 0.93980, saving model to resNet+parallel_32.hdf5\n",
      "77/77 [==============================] - 28s 368ms/step - loss: 0.1586 - acc: 0.9398 - val_loss: 1.1318 - val_acc: 0.5545 - lr: 1.0000e-04\n",
      "Epoch 4/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.1334 - acc: 0.9464\n",
      "Epoch 4: acc improved from 0.93980 to 0.94636, saving model to resNet+parallel_32.hdf5\n",
      "77/77 [==============================] - 28s 361ms/step - loss: 0.1334 - acc: 0.9464 - val_loss: 0.7219 - val_acc: 0.5545 - lr: 1.0000e-04\n",
      "Epoch 5/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0908 - acc: 0.9697\n",
      "Epoch 5: acc improved from 0.94636 to 0.96970, saving model to resNet+parallel_32.hdf5\n",
      "77/77 [==============================] - 29s 378ms/step - loss: 0.0908 - acc: 0.9697 - val_loss: 1.1864 - val_acc: 0.5545 - lr: 1.0000e-04\n",
      "Epoch 6/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0520 - acc: 0.9820\n",
      "Epoch 6: acc improved from 0.96970 to 0.98198, saving model to resNet+parallel_32.hdf5\n",
      "77/77 [==============================] - 30s 397ms/step - loss: 0.0520 - acc: 0.9820 - val_loss: 1.6729 - val_acc: 0.5545 - lr: 1.0000e-04\n",
      "Epoch 7/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0463 - acc: 0.9848\n",
      "Epoch 7: acc improved from 0.98198 to 0.98485, saving model to resNet+parallel_32.hdf5\n",
      "77/77 [==============================] - 34s 437ms/step - loss: 0.0463 - acc: 0.9848 - val_loss: 1.1374 - val_acc: 0.4269 - lr: 1.0000e-04\n",
      "Epoch 8/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0385 - acc: 0.9877\n",
      "Epoch 8: acc improved from 0.98485 to 0.98772, saving model to resNet+parallel_32.hdf5\n",
      "77/77 [==============================] - 33s 424ms/step - loss: 0.0385 - acc: 0.9877 - val_loss: 1.6023 - val_acc: 0.4223 - lr: 1.0000e-04\n",
      "Epoch 9/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0583 - acc: 0.9828\n",
      "Epoch 9: acc did not improve from 0.98772\n",
      "77/77 [==============================] - 34s 437ms/step - loss: 0.0583 - acc: 0.9828 - val_loss: 1.5495 - val_acc: 0.4896 - lr: 1.0000e-04\n",
      "Epoch 10/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0338 - acc: 0.9902\n",
      "Epoch 10: acc improved from 0.98772 to 0.99017, saving model to resNet+parallel_32.hdf5\n",
      "77/77 [==============================] - 36s 473ms/step - loss: 0.0338 - acc: 0.9902 - val_loss: 2.9496 - val_acc: 0.5545 - lr: 1.0000e-04\n",
      "Epoch 11/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0254 - acc: 0.9914\n",
      "Epoch 11: acc improved from 0.99017 to 0.99140, saving model to resNet+parallel_32.hdf5\n",
      "77/77 [==============================] - 35s 457ms/step - loss: 0.0254 - acc: 0.9914 - val_loss: 2.3535 - val_acc: 0.5963 - lr: 1.0000e-04\n",
      "Epoch 12/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0308 - acc: 0.9894\n",
      "Epoch 12: acc did not improve from 0.99140\n",
      "77/77 [==============================] - 33s 425ms/step - loss: 0.0308 - acc: 0.9894 - val_loss: 1.4905 - val_acc: 0.6659 - lr: 1.0000e-04\n",
      "Epoch 13/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0399 - acc: 0.9840\n",
      "Epoch 13: acc did not improve from 0.99140\n",
      "77/77 [==============================] - 36s 463ms/step - loss: 0.0399 - acc: 0.9840 - val_loss: 1.2731 - val_acc: 0.6798 - lr: 1.0000e-04\n",
      "Epoch 14/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0345 - acc: 0.9869\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n",
      "\n",
      "Epoch 14: acc did not improve from 0.99140\n",
      "77/77 [==============================] - 35s 452ms/step - loss: 0.0345 - acc: 0.9869 - val_loss: 1.4195 - val_acc: 0.7517 - lr: 1.0000e-04\n",
      "Epoch 15/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0304 - acc: 0.9889\n",
      "Epoch 15: acc did not improve from 0.99140\n",
      "77/77 [==============================] - 36s 464ms/step - loss: 0.0304 - acc: 0.9889 - val_loss: 0.7671 - val_acc: 0.8213 - lr: 8.0000e-05\n",
      "Epoch 16/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0171 - acc: 0.9951\n",
      "Epoch 16: acc improved from 0.99140 to 0.99509, saving model to resNet+parallel_32.hdf5\n",
      "77/77 [==============================] - 38s 499ms/step - loss: 0.0171 - acc: 0.9951 - val_loss: 0.8330 - val_acc: 0.8190 - lr: 8.0000e-05\n",
      "Epoch 17/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0154 - acc: 0.9959\n",
      "Epoch 17: acc improved from 0.99509 to 0.99590, saving model to resNet+parallel_32.hdf5\n",
      "77/77 [==============================] - 38s 490ms/step - loss: 0.0154 - acc: 0.9959 - val_loss: 0.8921 - val_acc: 0.8492 - lr: 8.0000e-05\n",
      "Epoch 18/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0507 - acc: 0.9840\n",
      "Epoch 18: acc did not improve from 0.99590\n",
      "77/77 [==============================] - 34s 444ms/step - loss: 0.0507 - acc: 0.9840 - val_loss: 0.5741 - val_acc: 0.7958 - lr: 8.0000e-05\n",
      "Epoch 19/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0193 - acc: 0.9934\n",
      "Epoch 19: acc did not improve from 0.99590\n",
      "77/77 [==============================] - 35s 456ms/step - loss: 0.0193 - acc: 0.9934 - val_loss: 0.6719 - val_acc: 0.8167 - lr: 8.0000e-05\n",
      "Epoch 20/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0058 - acc: 0.9992\n",
      "Epoch 20: acc improved from 0.99590 to 0.99918, saving model to resNet+parallel_32.hdf5\n",
      "77/77 [==============================] - 39s 510ms/step - loss: 0.0058 - acc: 0.9992 - val_loss: 0.6984 - val_acc: 0.8260 - lr: 8.0000e-05\n",
      "Epoch 21/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 21: acc improved from 0.99918 to 1.00000, saving model to resNet+parallel_32.hdf5\n",
      "77/77 [==============================] - 37s 486ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6946 - val_acc: 0.8515 - lr: 8.0000e-05\n",
      "Epoch 22/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0014 - acc: 0.9996\n",
      "Epoch 22: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 34s 448ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.7754 - val_acc: 0.8376 - lr: 8.0000e-05\n",
      "Epoch 23/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0035 - acc: 0.9984\n",
      "Epoch 23: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 455ms/step - loss: 0.0035 - acc: 0.9984 - val_loss: 0.7942 - val_acc: 0.8561 - lr: 8.0000e-05\n",
      "Epoch 24/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0062 - acc: 0.9975\n",
      "Epoch 24: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 456ms/step - loss: 0.0062 - acc: 0.9975 - val_loss: 0.8557 - val_acc: 0.8144 - lr: 8.0000e-05\n",
      "Epoch 25/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0059 - acc: 0.9980\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n",
      "\n",
      "Epoch 25: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 36s 464ms/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.7816 - val_acc: 0.8561 - lr: 8.0000e-05\n",
      "Epoch 26/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0084 - acc: 0.9975\n",
      "Epoch 26: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 457ms/step - loss: 0.0084 - acc: 0.9975 - val_loss: 0.7616 - val_acc: 0.8631 - lr: 6.4000e-05\n",
      "Epoch 27/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 27: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 37s 475ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.8076 - val_acc: 0.8515 - lr: 6.4000e-05\n",
      "Epoch 28/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - ETA: 0s - loss: 6.9392e-04 - acc: 1.0000\n",
      "Epoch 28: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 456ms/step - loss: 6.9392e-04 - acc: 1.0000 - val_loss: 0.8140 - val_acc: 0.8515 - lr: 6.4000e-05\n",
      "Epoch 29/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 3.8505e-04 - acc: 1.0000\n",
      "Epoch 29: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 462ms/step - loss: 3.8505e-04 - acc: 1.0000 - val_loss: 0.8315 - val_acc: 0.8515 - lr: 6.4000e-05\n",
      "Epoch 30/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 2.5959e-04 - acc: 1.0000\n",
      "Epoch 30: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 36s 463ms/step - loss: 2.5959e-04 - acc: 1.0000 - val_loss: 0.8377 - val_acc: 0.8631 - lr: 6.4000e-05\n",
      "Epoch 31/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0022 - acc: 0.9996    \n",
      "Epoch 31: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 454ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.8117 - val_acc: 0.8492 - lr: 6.4000e-05\n",
      "Epoch 32/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0536 - acc: 0.9840\n",
      "Epoch 32: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 36s 464ms/step - loss: 0.0536 - acc: 0.9840 - val_loss: 0.8489 - val_acc: 0.8167 - lr: 6.4000e-05\n",
      "Epoch 33/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0249 - acc: 0.9926\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.\n",
      "\n",
      "Epoch 33: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 36s 466ms/step - loss: 0.0249 - acc: 0.9926 - val_loss: 0.9121 - val_acc: 0.8422 - lr: 6.4000e-05\n",
      "Epoch 34/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0034 - acc: 0.9992\n",
      "Epoch 34: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 454ms/step - loss: 0.0034 - acc: 0.9992 - val_loss: 0.8610 - val_acc: 0.8561 - lr: 5.1200e-05\n",
      "Epoch 35/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0029 - acc: 0.9992\n",
      "Epoch 35: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 36s 458ms/step - loss: 0.0029 - acc: 0.9992 - val_loss: 0.8300 - val_acc: 0.8561 - lr: 5.1200e-05\n",
      "Epoch 36/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 9.4156e-04 - acc: 1.0000\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.\n",
      "\n",
      "Epoch 36: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 36s 461ms/step - loss: 9.4156e-04 - acc: 1.0000 - val_loss: 0.7614 - val_acc: 0.8631 - lr: 5.1200e-05\n",
      "Epoch 37/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 37: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 458ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.7295 - val_acc: 0.8677 - lr: 4.0960e-05\n",
      "Epoch 38/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 38: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 36s 466ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.7830 - val_acc: 0.8608 - lr: 4.0960e-05\n",
      "Epoch 39/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 5.7225e-04 - acc: 1.0000\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.\n",
      "\n",
      "Epoch 39: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 455ms/step - loss: 5.7225e-04 - acc: 1.0000 - val_loss: 0.8231 - val_acc: 0.8631 - lr: 4.0960e-05\n",
      "Epoch 40/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 3.4255e-04 - acc: 1.0000\n",
      "Epoch 40: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 36s 463ms/step - loss: 3.4255e-04 - acc: 1.0000 - val_loss: 0.8247 - val_acc: 0.8631 - lr: 3.2768e-05\n",
      "Epoch 41/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 2.3980e-04 - acc: 1.0000\n",
      "Epoch 41: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 36s 466ms/step - loss: 2.3980e-04 - acc: 1.0000 - val_loss: 0.8334 - val_acc: 0.8654 - lr: 3.2768e-05\n",
      "Epoch 42/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 2.4273e-04 - acc: 1.0000\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.\n",
      "\n",
      "Epoch 42: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 461ms/step - loss: 2.4273e-04 - acc: 1.0000 - val_loss: 0.8375 - val_acc: 0.8724 - lr: 3.2768e-05\n",
      "Epoch 43/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 2.5270e-04 - acc: 1.0000\n",
      "Epoch 43: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 36s 466ms/step - loss: 2.5270e-04 - acc: 1.0000 - val_loss: 0.8488 - val_acc: 0.8677 - lr: 2.6214e-05\n",
      "Epoch 44/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 2.2048e-04 - acc: 1.0000\n",
      "Epoch 44: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 458ms/step - loss: 2.2048e-04 - acc: 1.0000 - val_loss: 0.8463 - val_acc: 0.8701 - lr: 2.6214e-05\n",
      "Epoch 45/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 1.7988e-04 - acc: 1.0000\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.\n",
      "\n",
      "Epoch 45: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 460ms/step - loss: 1.7988e-04 - acc: 1.0000 - val_loss: 0.8485 - val_acc: 0.8724 - lr: 2.6214e-05\n",
      "Epoch 46/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 1.7026e-04 - acc: 1.0000\n",
      "Epoch 46: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 36s 467ms/step - loss: 1.7026e-04 - acc: 1.0000 - val_loss: 0.8681 - val_acc: 0.8701 - lr: 2.0972e-05\n",
      "Epoch 47/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 1.3801e-04 - acc: 1.0000\n",
      "Epoch 47: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 455ms/step - loss: 1.3801e-04 - acc: 1.0000 - val_loss: 0.8703 - val_acc: 0.8677 - lr: 2.0972e-05\n",
      "Epoch 48/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 2.3186e-04 - acc: 1.0000\n",
      "Epoch 48: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 36s 472ms/step - loss: 2.3186e-04 - acc: 1.0000 - val_loss: 0.8810 - val_acc: 0.8631 - lr: 2.0972e-05\n",
      "Epoch 49/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 1.6067e-04 - acc: 1.0000\n",
      "Epoch 49: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 452ms/step - loss: 1.6067e-04 - acc: 1.0000 - val_loss: 0.8776 - val_acc: 0.8631 - lr: 2.0972e-05\n",
      "Epoch 50/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 2.1481e-04 - acc: 1.0000\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 1.6777214477770033e-05.\n",
      "\n",
      "Epoch 50: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 456ms/step - loss: 2.1481e-04 - acc: 1.0000 - val_loss: 0.8932 - val_acc: 0.8631 - lr: 2.0972e-05\n",
      "Epoch 51/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 3.5237e-04 - acc: 1.0000\n",
      "Epoch 51: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 37s 479ms/step - loss: 3.5237e-04 - acc: 1.0000 - val_loss: 0.8742 - val_acc: 0.8677 - lr: 1.6777e-05\n",
      "Epoch 52/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 1.4035e-04 - acc: 1.0000\n",
      "Epoch 52: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 450ms/step - loss: 1.4035e-04 - acc: 1.0000 - val_loss: 0.8949 - val_acc: 0.8677 - lr: 1.6777e-05\n",
      "Epoch 53/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 2.1187e-04 - acc: 1.0000\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 1.3421771291177721e-05.\n",
      "\n",
      "Epoch 53: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 36s 474ms/step - loss: 2.1187e-04 - acc: 1.0000 - val_loss: 0.8948 - val_acc: 0.8631 - lr: 1.6777e-05\n",
      "Epoch 54/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 7.6145e-05 - acc: 1.0000\n",
      "Epoch 54: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 459ms/step - loss: 7.6145e-05 - acc: 1.0000 - val_loss: 0.8994 - val_acc: 0.8654 - lr: 1.3422e-05\n",
      "Epoch 55/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 3.9683e-04 - acc: 0.9996\n",
      "Epoch 55: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 36s 475ms/step - loss: 3.9683e-04 - acc: 0.9996 - val_loss: 0.9182 - val_acc: 0.8654 - lr: 1.3422e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 2.3376e-04 - acc: 1.0000\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 1.0737417323980481e-05.\n",
      "\n",
      "Epoch 56: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 459ms/step - loss: 2.3376e-04 - acc: 1.0000 - val_loss: 0.9087 - val_acc: 0.8631 - lr: 1.3422e-05\n",
      "Epoch 57/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 1.9109e-04 - acc: 1.0000\n",
      "Epoch 57: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 457ms/step - loss: 1.9109e-04 - acc: 1.0000 - val_loss: 0.9029 - val_acc: 0.8585 - lr: 1.0737e-05\n",
      "Epoch 58/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 4.4501e-04 - acc: 1.0000\n",
      "Epoch 58: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 37s 480ms/step - loss: 4.4501e-04 - acc: 1.0000 - val_loss: 0.9041 - val_acc: 0.8608 - lr: 1.0737e-05\n",
      "Epoch 59/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 1.3380e-04 - acc: 1.0000\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 8.589933713665232e-06.\n",
      "\n",
      "Epoch 59: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 455ms/step - loss: 1.3380e-04 - acc: 1.0000 - val_loss: 0.9024 - val_acc: 0.8585 - lr: 1.0737e-05\n",
      "Epoch 60/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 1.0873e-04 - acc: 1.0000\n",
      "Epoch 60: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 37s 481ms/step - loss: 1.0873e-04 - acc: 1.0000 - val_loss: 0.9098 - val_acc: 0.8585 - lr: 8.5899e-06\n",
      "Epoch 61/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 1.1311e-04 - acc: 1.0000\n",
      "Epoch 61: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 36s 471ms/step - loss: 1.1311e-04 - acc: 1.0000 - val_loss: 0.9127 - val_acc: 0.8608 - lr: 8.5899e-06\n",
      "Epoch 62/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 9.4763e-05 - acc: 1.0000\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 6.871946970932186e-06.\n",
      "\n",
      "Epoch 62: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 454ms/step - loss: 9.4763e-05 - acc: 1.0000 - val_loss: 0.9132 - val_acc: 0.8585 - lr: 8.5899e-06\n",
      "Epoch 63/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 1.2898e-04 - acc: 1.0000\n",
      "Epoch 63: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 37s 479ms/step - loss: 1.2898e-04 - acc: 1.0000 - val_loss: 0.9170 - val_acc: 0.8608 - lr: 6.8719e-06\n",
      "Epoch 64/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 6.8719e-05 - acc: 1.0000\n",
      "Epoch 64: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 36s 475ms/step - loss: 6.8719e-05 - acc: 1.0000 - val_loss: 0.9205 - val_acc: 0.8608 - lr: 6.8719e-06\n",
      "Epoch 65/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 6.6844e-05 - acc: 1.0000\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 5.497557503986173e-06.\n",
      "\n",
      "Epoch 65: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 462ms/step - loss: 6.6844e-05 - acc: 1.0000 - val_loss: 0.9224 - val_acc: 0.8608 - lr: 6.8719e-06\n",
      "Epoch 66/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 1.3367e-04 - acc: 1.0000\n",
      "Epoch 66: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 36s 470ms/step - loss: 1.3367e-04 - acc: 1.0000 - val_loss: 0.9259 - val_acc: 0.8608 - lr: 5.4976e-06\n",
      "Epoch 67/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 9.4148e-05 - acc: 1.0000\n",
      "Epoch 67: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 36s 469ms/step - loss: 9.4148e-05 - acc: 1.0000 - val_loss: 0.9267 - val_acc: 0.8608 - lr: 5.4976e-06\n",
      "Epoch 68/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 9.1191e-05 - acc: 1.0000\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 4.398046075948514e-06.\n",
      "\n",
      "Epoch 68: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 36s 474ms/step - loss: 9.1191e-05 - acc: 1.0000 - val_loss: 0.9259 - val_acc: 0.8585 - lr: 5.4976e-06\n",
      "Epoch 69/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 8.1792e-05 - acc: 1.0000\n",
      "Epoch 69: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 36s 469ms/step - loss: 8.1792e-05 - acc: 1.0000 - val_loss: 0.9315 - val_acc: 0.8608 - lr: 4.3980e-06\n",
      "Epoch 70/70\n",
      "77/77 [==============================] - ETA: 0s - loss: 5.8344e-05 - acc: 1.0000\n",
      "Epoch 70: acc did not improve from 1.00000\n",
      "77/77 [==============================] - 35s 451ms/step - loss: 5.8344e-05 - acc: 1.0000 - val_loss: 0.9310 - val_acc: 0.8561 - lr: 4.3980e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_x,X_train_x],y_train_x,\n",
    "                    validation_data=([X_valid,X_valid],y_valid),\n",
    "                    epochs=70,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[lr_decay,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e0ea93f",
   "metadata": {
    "id": "3e0ea93f",
    "outputId": "671830f0-6787-4d1d-a001-90be648c6e5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 6s 149ms/step - loss: 1.0040 - acc: 0.8360\n",
      "Hyperparameters : {'name': 'Adam', 'learning_rate': 4.3980463e-06, 'decay': 1e-05, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False} \n",
      "\n",
      "Test loss: 1.004006266593933\n",
      "Test accuracy: 0.8360389471054077\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate([X_test,X_test],y_test,batch_size = 32)\n",
    "print(\"Hyperparameters : {} \\n\".format(model.optimizer.get_config()))\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5fa9c77",
   "metadata": {
    "id": "f5fa9c77",
    "outputId": "29efba75-1664-424f-88a1-58d69e2dcaae"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the graph of accuracy VS epoch\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'],loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#Plotting the graph of loss VS epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db092c6e",
   "metadata": {
    "id": "db092c6e",
    "outputId": "2da48481-40f8-48a1-92aa-de22ed9afad1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plot-metric in /home/deepak1010/anaconda3/lib/python3.9/site-packages (0.0.6)\n",
      "Requirement already satisfied: scikit-learn>=0.21.2 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.24.2)\n",
      "Requirement already satisfied: pandas>=0.23.4 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.20.3)\n",
      "Requirement already satisfied: matplotlib>=3.0.2 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (3.4.3)\n",
      "Requirement already satisfied: colorlover>=0.3.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.3.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (1.7.1)\n",
      "Requirement already satisfied: seaborn>=0.9.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from plot-metric) (0.11.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.0.2->plot-metric) (1.3.1)\n",
      "Requirement already satisfied: six in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from cycler>=0.10->matplotlib>=3.0.2->plot-metric) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from pandas>=0.23.4->plot-metric) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot-metric) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/deepak1010/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.21.2->plot-metric) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plot-metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9bae563a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 4s 169ms/step\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 0 0 0]\n",
      "Confusion Matrix\n",
      "[[670   0]\n",
      " [562   0]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "non-melanoma       0.54      1.00      0.70       670\n",
      "    melanoma       0.00      0.00      0.00       562\n",
      "\n",
      "    accuracy                           0.54      1232\n",
      "   macro avg       0.27      0.50      0.35      1232\n",
      "weighted avg       0.30      0.54      0.38      1232\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sn\n",
    "B = np.reshape(y_test, (-1, 2))\n",
    "Y_pred = model.predict([X_test,X_test], 240 // 4)\n",
    "\n",
    "#print(type(Y_pred))\n",
    "print(y_test)  \n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print(y_pred)\n",
    "print('Confusion Matrix')\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['non-melanoma', 'melanoma']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(matrix,annot=True,fmt='d')\n",
    "plt.xlabel('Predicted value')\n",
    "plt.ylabel('Truth')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b083933",
   "metadata": {
    "id": "3b083933",
    "outputId": "ab3411d9-94d8-4cd5-d518-9b023c600113"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plot_metric.functions import BinaryClassification\n",
    "# Visualisation with plot_metric\n",
    "y_true = y_test\n",
    "y_probas = y_pred\n",
    "bc = BinaryClassification(y_true, y_probas, labels=['non-melanoma', 'melanoma'])\n",
    "\n",
    "# Figures\n",
    "plt.figure(figsize=(5,5))\n",
    "bc.plot_roc_curve()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee18da1",
   "metadata": {
    "id": "8ee18da1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ResNet+DenseNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.13.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
